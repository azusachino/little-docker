filter {
        grok {
                #使用多条匹配规则匹配不同的日志
                match => [
                        "message", "%{URIHOST:http_host} %{IP:server_addr} %{IP:remote_addr} \[%{HTTPDATE:timestamp}\] \"%{WORD:verb} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}\" (?<access_requerst_body>-) %{NUMBER:http_status_code} %{NUMBER:bytes} \"(?:%{GREEDYDATA:http_referrer}|-)\" \"(%{GREEDYDATA:user_agent}|-)\" (%{URIHOST:request_time}|-) (%{URIHOST:upstream_response_time}|-)",
                        "message", "%{URIHOST:http_host} %{IP:server_addr} %{IP:remote_addr} \[%{HTTPDATE:timestamp}\] \"%{WORD:verb} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}\" ({%{NOTSPACE:test_requerst_body}}) %{NUMBER:http_status_code} %{NUMBER:bytes} \"(?:%{GREEDYDATA:http_referrer}|-)\" \"(%{GREEDYDATA:user_agent}|-)\" (%{URIHOST:request_time}|-) (%{URIHOST:upstream_response_time}|-)",
                        "message", "%{URIHOST:http_host} %{IP:server_addr} %{IP:remote_addr} \[%{HTTPDATE:timestamp}\] \"%{WORD:verb} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}\" (?<test2__requerst_body>\S+ \S+) %{NUMBER:http_status_code} %{NUMBER:bytes} \"(?:%{GREEDYDATA:http_referrer}|-)\" \"(%{GREEDYDATA:user_agent}|-)\" (%{URIHOST:request_time}|-) (%{URIHOST:upstream_response_time}|-)",
                        "message", "%{URIHOST:http_host} %{IP:server_addr} %{IP:remote_addr} \[%{HTTPDATE:timestamp}\] \"%{WORD:verb} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}\" %{NOTSPACE:requerst_body} %{NUMBER:http_status_code} %{NUMBER:bytes} \"(?:%{GREEDYDATA:http_referrer}|-)\" \"(%{GREEDYDATA:user_agent}|-)\" (%{URIHOST:request_time}|-) (%{URIHOST:upstream_response_time}|-)",
                        "message", "%{URIHOST:http_host} %{IP:server_addr} %{IP:remote_addr} \[%{HTTPDATE:timestamp}\] \"%{WORD:verb} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}\" ({(?<test3_requerst_body>(\S+ \S+ )+\S+|(\S+ \S+)+)}) %{NUMBER:http_status_code} %{NUMBER:bytes} \"(?:%{GREEDYDATA:http_referrer}|-)\" \"(%{GREEDYDATA:user_agent}|-)\" (%{URIHOST:request_time}|-) (%{URIHOST:upstream_response_time}|-)",
                        "message", "(?<datetime>\d\d\d\d/\d\d/\d\d \d\d:\d\d:\d\d) \[(?<errtype>\w+)\] (?<other1>\S+:) \*\d+ (?<errmsg>[^,]+), (?<errinfo>.*)$",
                        "message", "(?<datetime>\d\d\d\d/\d\d/\d\d \d\d:\d\d:\d\d) \[(?<errtype>\w+)\] (?<other1>\S+:) (?<errmsg>[^,]+)"
                ]
                #日志匹配完成后，将匹配到的“message”删除，所匹配的到的日志就是对”message”日志的切割复制。
                remove_field => "message"
        }   
 
# 将zabbix及python监控产生的日志删除
  if [user_agent] == "Zabbix" {  
                  drop {}  
                 }  
  if [user_agent] == "python-requests/2.18.1" {  
                   drop {}  
                 }  
# 将日志中类似"FR=mK"的字段去掉，将没用的字段删除，字段过多影响性能及占用空间
        mutate {
                 gsub => [
                        "requerst_body", "[a-zA-Z0-9]{2}=[A-Za-z]{4}&|&[a-zA-Z0-9]{2}=[A-Za-z]{4}", ""
                 ]
        }
 
 # 使用kv对过滤出来的nginx日志body部分再次过滤
        kv {
                 source => "requerst_body"
                 field_split => "&"
                 remove_field => ["buyerPayAmount","buyerId","source","invoiceAmount","connectSys","sign","mid","settleDate","mchntUuid","tid","couponAmount","goodsTradeNo","targetOrderId","notifyId","subInst","seqId","merOrderId","beat","createTime","billQRCode","billDesc"]
        }
 
# 对部分字符解码
        urldecode {
                 all_fields => true
        }
# 将billPayment中的"\",","{}"字符去掉
        mutate {
                 gsub => [
                        "billPayment", "[\\\"\{\}]", ""
                 ]
        }
 
# 使用kv插件再次对billPayment切割
if [billPayment]{
       kv {
                 source => "billPayment"
                 field_split => "\,"
                 value_split => ":"
                 remove_field => ["merOrderId","billDate","buyerUsername","settleDate","buyerId","couponAmount","billBizType","targetOrderId","billNo","paySeqId","billPayment","buyerPayAmount","invoiceAmount","billFunds","srcReverse","attachedData"]
        }
}
 
# 使用kv插件切割错误日志
if [errinfo] {
        kv {
                source => "errinfo"
                field_split => "\,"
                value_split => ":"
        }
}
 
# 过滤不同日志中交易金额以便统计总交易额
        grok {
                match =>  [
                        "totalAmount", "(?<pay3_money>([0-9]{1,}))(?<pay4_money>([0-9]{2})$)"
               ]
        }

        date {
            match => [ "timestamp" , "yyyy-MM-dd HH:mm:ss,S", "ISO8601" ]
        }
 
# 将交易额中的以分为单位字符串转化为以元为单位
#如果交易金额为一位数则进行下面的过滤规则
        if [totalAmount] =~ "^[1-9]$" {
                mutate {
                        replace => { "pay_money" => "0.0%{totalAmount}" }
                }
        }
 
 #如果交易金额为两位数则进行下面的过滤规则
        if [totalAmount]=~ "^[1-9][0-9]$" {
                mutate {
                        replace => { "pay_money" => "0.%{totalAmount }" }
                }
        }
 
 #如果交易金额为三位数则进行下面的过滤规则
        if [totalAmount] =~ "[0-9]{3,}" {
                mutate {
                        replace => { "pay_money" => "%{pay3_money}.%{pay4_money}" }
                }
        }
 
# 更改部分字段数据格式以方便在kibana中统计
        dissect {
               convert_datatype => {
                        totalAmount => "float"
                        request_time => "float"
                        pay_money => "float"
                        upstream_response_time => "float"
                        http_status_code => "int"
                        bytes => "int"
                        total_amount => "float"
                }
        }
 
# 统计ip地址来源
       if [remote_addr] !~ "^127\.|^192\.168\.|^172\.1[6-9]\.|^172\.2[0-9]\.|^172\.3[01]\.|^10\." {
                geoip {
                        source => "remote_addr"
                        target => "geoip"
                        database => "/etc/logstash/GeoLite2-City.mmdb"
                }
        }
}